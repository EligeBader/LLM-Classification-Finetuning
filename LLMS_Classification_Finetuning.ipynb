{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this workbook, I preprocess and clean text data, vectorize it using TF-IDF, and train a Logistic Regression model to predict the winning response between two models. Additionally, I fine-tune a BERT model for the same task. The purpose of this workbook is to compare the performance of traditional machine learning models with transformer-based models in the context of large language models (LLMs) projects. I use log loss as the evaluation metric to measure the performance of our models, ensuring that our predictions are probabilistically accurate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2XCQdtK6_8j"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkKYBvQ-6_8k"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import log_loss\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.linear_model import LogisticRegression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-eENd9d6_8l",
        "outputId": "c2d6a973-be0f-4134-8718-5cc6aef115ba"
      },
      "outputs": [],
      "source": [
        "# Download necessary NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOz4ldJK6_8l"
      },
      "outputs": [],
      "source": [
        "# Initialize the lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOd6WVHj6_8l"
      },
      "source": [
        "# Load train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "wR6tjoG96_8m",
        "outputId": "d818200c-f441-4fa6-ac14-832466cd7bea"
      },
      "outputs": [],
      "source": [
        "train_data = pd.read_parquet('train.parquet', engine='pyarrow')\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYCr2yOE6_8m"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    \n",
        "    '''\n",
        "    Cleans the input text by performing the following steps:\n",
        "    1. Converts text to lowercase.\n",
        "    2. Tokenizes the text into words.\n",
        "    3. Removes punctuation and non-alphabetic tokens.\n",
        "    4. Removes stopwords.\n",
        "    5. Lemmatizes the tokens.\n",
        "    6. Joins the tokens back into a single string.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The input text to be cleaned.\n",
        "\n",
        "    Returns:\n",
        "    str: The cleaned text.\n",
        "    '''\n",
        "\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word.isalpha()] # Remove punctuation and non-alphabetic tokens\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    clean_text = ' '.join(tokens)\n",
        "    return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKwVJ7L86_8m"
      },
      "outputs": [],
      "source": [
        "# clean the text data\n",
        "train_data['prompt'] = train_data['prompt'].apply(clean_text)\n",
        "train_data['response_a'] = train_data['response_a'].apply(clean_text)\n",
        "train_data['response_b'] = train_data['response_b'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "gfhLQSUG6_8m",
        "outputId": "be34301c-dcd6-43f2-a844-3364f212b8a0"
      },
      "outputs": [],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s9qw5DK66_8m"
      },
      "outputs": [],
      "source": [
        "# Combine responses for TF-IDF vectorization\n",
        "train_data['combined_responses'] = train_data['response_a'] + \" \" + train_data['response_b']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "4gPYtwXN6_8m",
        "outputId": "cda3f60a-24c9-4a0f-bd28-07645999942b"
      },
      "outputs": [],
      "source": [
        "train_data[['response_a', 'response_b', 'combined_responses']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iMXs4-ghdqv"
      },
      "outputs": [],
      "source": [
        "# Sample the data\n",
        "sampled_data = train_data.sample(n=10000, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1S9VmWuJkrrf",
        "outputId": "cf462519-b67e-437d-c3f5-52483546caa3"
      },
      "outputs": [],
      "source": [
        "sampled_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBAPiERI6_8n"
      },
      "outputs": [],
      "source": [
        "# Vectorize text using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(sampled_data['combined_responses'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHfbQ9Fk6_8n",
        "outputId": "70130b39-ffb3-476f-e944-0505136c04b8"
      },
      "outputs": [],
      "source": [
        "# Target variable\n",
        "sampled_data[['winner_model_a', 'winner_model_b', 'winner_tie']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mqiJCQjN6_8n"
      },
      "outputs": [],
      "source": [
        "# Encode target variable\n",
        "sampled_data['winner'] = sampled_data[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1)\n",
        "sampled_data['winner'] = sampled_data['winner'].map({'winner_model_a': 0, 'winner_model_b': 1, 'winner_tie': 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "60c2UJIL6_8n"
      },
      "outputs": [],
      "source": [
        "# target variable\n",
        "y = sampled_data['winner'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejii18pk6_8n"
      },
      "outputs": [],
      "source": [
        "# train_test\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCdClFKz6_8n",
        "outputId": "3eab1461-3a99-46e2-b6e4-6385bd117fb0"
      },
      "outputs": [],
      "source": [
        "# Check the shapes\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ0aU8sM6_8n"
      },
      "source": [
        "### Model 1: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "zKR1XDQj6_8o",
        "outputId": "e26ef63d-1b17-420d-dc37-26dadd682c38"
      },
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "model_LR = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model_LR.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir5XtApX6_8o"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the validation set\n",
        "y_pred_LR = model_LR.predict_proba(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x4obCHE6_8o",
        "outputId": "efd4d192-7782-4795-b66a-e501f47f9569"
      },
      "outputs": [],
      "source": [
        "# Calculate log loss\n",
        "log_loss_score_LR = log_loss(y_val, y_pred_LR)\n",
        "print(f'Log Loss: {log_loss_score_LR}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DVaDl256_8o",
        "outputId": "eb5a98e5-23e4-419f-b68e-9e7cd87c66fa"
      },
      "outputs": [],
      "source": [
        "# Load the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tokenize the text data\n",
        "def encode_data(texts):\n",
        "    \"\"\"\n",
        "    Tokenizes the input texts using the BERT tokenizer.\n",
        "\n",
        "    Parameters:\n",
        "    texts (list of str): List of input texts to be tokenized.\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary containing tokenized input ids, attention masks, and token type ids.\n",
        "    \"\"\"\n",
        "    return tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "# Tokenize the combined responses from the sampled data\n",
        "train_encodings = encode_data(sampled_data['combined_responses'].tolist())\n",
        "\n",
        "# Convert the winner column to a tensor of labels\n",
        "labels = torch.tensor(sampled_data['winner'].values, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jhjjA_rL6_8o"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(sampled_data['combined_responses'], labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the split text data\n",
        "train_encodings = encode_data(train_texts.tolist())\n",
        "val_encodings = encode_data(val_texts.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA8dl1dO6_8o"
      },
      "outputs": [],
      "source": [
        "# Define a custom dataset\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        \"\"\"\n",
        "        Initializes the CustomDataset with encodings and labels.\n",
        "\n",
        "        Parameters:\n",
        "        encodings (dict): Encoded input data.\n",
        "        labels (torch.Tensor): Corresponding labels for the input data.\n",
        "        \"\"\"\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieves the item (encoding and label) at the specified index.\n",
        "\n",
        "        Parameters:\n",
        "        idx (int): Index of the item to retrieve.\n",
        "\n",
        "        Returns:\n",
        "        dict: A dictionary containing the encoding and label for the specified index.\n",
        "        \"\"\"\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of items in the dataset.\n",
        "        \n",
        "        \"\"\"\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmHyAPfa6_8o"
      },
      "outputs": [],
      "source": [
        "#  Create a CustomDataset object for the training and validation sets\n",
        "train_dataset = CustomDataset(train_encodings, train_labels)\n",
        "val_dataset = CustomDataset(val_encodings, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2Dm0RcS6_8o"
      },
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sBk85Ww6_8o"
      },
      "outputs": [],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khUgjKtu6_8o",
        "outputId": "ab3bec23-c022-4cd0-df46-6604896319e3"
      },
      "outputs": [],
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eNd_F_5L6_8o",
        "outputId": "e9bb89e2-3a14-4c45-f46f-645869776e86"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "MhoT7wmF6_8o",
        "outputId": "29e7fa5a-5855-48b2-8b0d-723d35b69703"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGKgvqAlAOb6"
      },
      "source": [
        "### Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kw_PBvwK_-Sy"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess test data\n",
        "test_data = pd.read_parquet('test.parquet', engine='pyarrow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4Uftc_7ANx7"
      },
      "outputs": [],
      "source": [
        "# Clean the text data\n",
        "test_data['prompt'] = test_data['prompt'].apply(clean_text)\n",
        "test_data['response_a'] = test_data['response_a'].apply(clean_text)\n",
        "test_data['response_b'] = test_data['response_b'].apply(clean_text)\n",
        "test_data['combined_responses'] = test_data['response_a'] + \" \" + test_data['response_b']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-v_8TogzAIsr"
      },
      "outputs": [],
      "source": [
        "# Vectorize test data\n",
        "X_test = vectorizer.transform(test_data['combined_responses'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgxxb7gjAIpL",
        "outputId": "34e0d5b1-0d0b-4674-84af-738cef33ee8b"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data using Logistic Regression model\n",
        "y_test_pred_LR = model_LR.predict_proba(X_test)\n",
        "print(f'Test Predictions (Logistic Regression): {y_test_pred_LR}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOQugzHOAInH"
      },
      "outputs": [],
      "source": [
        "# Tokenize the test data\n",
        "test_encodings = encode_data(test_data['combined_responses'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0cW87x2_-8c"
      },
      "outputs": [],
      "source": [
        "# Move test encodings to device\n",
        "test_encodings = {key: val.to(device) for key, val in test_encodings.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE-o-Hd6AURS"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data using BERT model\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    outputs = model(**test_encodings)\n",
        "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1).cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtU-IJ1bAWG-"
      },
      "outputs": [],
      "source": [
        "# Prepare the submission file\n",
        "submission = pd.DataFrame(predictions, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])\n",
        "submission.insert(0, 'id', test_data['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppsujL4ZAXdN",
        "outputId": "3c129761-cb9a-4e1d-a308-a5cf18c1a58e"
      },
      "outputs": [],
      "source": [
        "# Save the submission file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print('Submission file created!')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
