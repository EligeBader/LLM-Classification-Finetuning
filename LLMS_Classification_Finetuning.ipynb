{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this workbook, I preprocess and clean text data, vectorize it using TF-IDF, and train a Logistic Regression model to predict the winning response between two models. Additionally, I fine-tune a BERT model for the same task. The purpose of this workbook is to compare the performance of traditional machine learning models with transformer-based models in the context of large language models (LLMs) projects. I use log loss as the evaluation metric to measure the performance of our models, ensuring that our predictions are probabilistically accurate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2XCQdtK6_8j"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkKYBvQ-6_8k"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\elige\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\elige\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import log_loss\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-eENd9d6_8l",
        "outputId": "c2d6a973-be0f-4134-8718-5cc6aef115ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\elige\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\elige\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\elige\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\elige\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Download necessary NLTK data files\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "BOz4ldJK6_8l"
      },
      "outputs": [],
      "source": [
        "# Initialize the lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOd6WVHj6_8l"
      },
      "source": [
        "# Load train Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "id": "wR6tjoG96_8m",
        "outputId": "d818200c-f441-4fa6-ac14-832466cd7bea"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[\"Is it morally right to try to have a certain...</td>\n",
              "      <td>[\"The question of whether it is morally right ...</td>\n",
              "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>[\"What is the difference between marriage lice...</td>\n",
              "      <td>[\"A marriage license is a legal document that ...</td>\n",
              "      <td>[\"A marriage license and a marriage certificat...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65089</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>mistral-medium</td>\n",
              "      <td>[\"explain function calling. how would you call...</td>\n",
              "      <td>[\"Function calling is the process of invoking ...</td>\n",
              "      <td>[\"Function calling is the process of invoking ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96401</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>mistral-7b-instruct</td>\n",
              "      <td>[\"How can I create a test set for a very rare ...</td>\n",
              "      <td>[\"Creating a test set for a very rare category...</td>\n",
              "      <td>[\"When building a classifier for a very rare c...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198779</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>[\"What is the best way to travel from Tel-Aviv...</td>\n",
              "      <td>[\"The best way to travel from Tel Aviv to Jeru...</td>\n",
              "      <td>[\"The best way to travel from Tel-Aviv to Jeru...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id             model_a              model_b  \\\n",
              "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
              "1   53567           koala-13b           gpt-4-0613   \n",
              "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
              "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
              "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  [\"Is it morally right to try to have a certain...   \n",
              "1  [\"What is the difference between marriage lice...   \n",
              "2  [\"explain function calling. how would you call...   \n",
              "3  [\"How can I create a test set for a very rare ...   \n",
              "4  [\"What is the best way to travel from Tel-Aviv...   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  [\"The question of whether it is morally right ...   \n",
              "1  [\"A marriage license is a legal document that ...   \n",
              "2  [\"Function calling is the process of invoking ...   \n",
              "3  [\"Creating a test set for a very rare category...   \n",
              "4  [\"The best way to travel from Tel Aviv to Jeru...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
              "1  [\"A marriage license and a marriage certificat...               0   \n",
              "2  [\"Function calling is the process of invoking ...               0   \n",
              "3  [\"When building a classifier for a very rare c...               1   \n",
              "4  [\"The best way to travel from Tel-Aviv to Jeru...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  \n",
              "0               0           0  \n",
              "1               1           0  \n",
              "2               0           1  \n",
              "3               0           0  \n",
              "4               1           0  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rain_data = pd.read_parquet('train.parquet', engine='pyarrow')\n",
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vYCr2yOE6_8m"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    \n",
        "    '''\n",
        "    Cleans the input text by performing the following steps:\n",
        "    1. Converts text to lowercase.\n",
        "    2. Tokenizes the text into words.\n",
        "    3. Removes punctuation and non-alphabetic tokens.\n",
        "    4. Removes stopwords.\n",
        "    5. Lemmatizes the tokens.\n",
        "    6. Joins the tokens back into a single string.\n",
        "\n",
        "    Parameters:\n",
        "    text (str): The input text to be cleaned.\n",
        "\n",
        "    Returns:\n",
        "    str: The cleaned text.\n",
        "    '''\n",
        "\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [word for word in tokens if word.isalpha()] # Remove punctuation and non-alphabetic tokens\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    clean_text = ' '.join(tokens)\n",
        "    return clean_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKwVJ7L86_8m"
      },
      "outputs": [],
      "source": [
        "# clean the text data\n",
        "train_data['prompt'] = train_data['prompt'].apply(clean_text)\n",
        "train_data['response_a'] = train_data['response_a'].apply(clean_text)\n",
        "train_data['response_b'] = train_data['response_b'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "gfhLQSUG6_8m",
        "outputId": "be34301c-dcd6-43f2-a844-3364f212b8a0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30192</td>\n",
              "      <td>gpt-4-1106-preview</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>morally right try certain percentage female ma...</td>\n",
              "      <td>question whether morally right aim certain per...</td>\n",
              "      <td>ai personal belief opinion however tell questi...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>53567</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-4-0613</td>\n",
              "      <td>difference marriage license marriage certifica...</td>\n",
              "      <td>marriage license legal document allows couple ...</td>\n",
              "      <td>marriage license marriage certificate two diff...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>65089</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>mistral-medium</td>\n",
              "      <td>explain function calling would call function</td>\n",
              "      <td>function calling process invoking executing fu...</td>\n",
              "      <td>function calling process invoking function pro...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>96401</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>mistral-7b-instruct</td>\n",
              "      <td>create test set rare category want build class...</td>\n",
              "      <td>creating test set rare category challenging ma...</td>\n",
              "      <td>building classifier rare category creating tes...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>198779</td>\n",
              "      <td>koala-13b</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>best way travel jerusalem car bus plane</td>\n",
              "      <td>best way travel tel aviv jerusalem depends per...</td>\n",
              "      <td>best way travel jerusalem depends personal pre...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id             model_a              model_b  \\\n",
              "0   30192  gpt-4-1106-preview           gpt-4-0613   \n",
              "1   53567           koala-13b           gpt-4-0613   \n",
              "2   65089  gpt-3.5-turbo-0613       mistral-medium   \n",
              "3   96401    llama-2-13b-chat  mistral-7b-instruct   \n",
              "4  198779           koala-13b   gpt-3.5-turbo-0314   \n",
              "\n",
              "                                              prompt  \\\n",
              "0  morally right try certain percentage female ma...   \n",
              "1  difference marriage license marriage certifica...   \n",
              "2       explain function calling would call function   \n",
              "3  create test set rare category want build class...   \n",
              "4            best way travel jerusalem car bus plane   \n",
              "\n",
              "                                          response_a  \\\n",
              "0  question whether morally right aim certain per...   \n",
              "1  marriage license legal document allows couple ...   \n",
              "2  function calling process invoking executing fu...   \n",
              "3  creating test set rare category challenging ma...   \n",
              "4  best way travel tel aviv jerusalem depends per...   \n",
              "\n",
              "                                          response_b  winner_model_a  \\\n",
              "0  ai personal belief opinion however tell questi...               1   \n",
              "1  marriage license marriage certificate two diff...               0   \n",
              "2  function calling process invoking function pro...               0   \n",
              "3  building classifier rare category creating tes...               1   \n",
              "4  best way travel jerusalem depends personal pre...               0   \n",
              "\n",
              "   winner_model_b  winner_tie  \n",
              "0               0           0  \n",
              "1               1           0  \n",
              "2               0           1  \n",
              "3               0           0  \n",
              "4               1           0  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "s9qw5DK66_8m"
      },
      "outputs": [],
      "source": [
        "# Combine responses for TF-IDF vectorization\n",
        "train_data['combined_responses'] = train_data['response_a'] + \" \" + train_data['response_b']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "4gPYtwXN6_8m",
        "outputId": "cda3f60a-24c9-4a0f-bd28-07645999942b"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>combined_responses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>question whether morally right aim certain per...</td>\n",
              "      <td>ai personal belief opinion however tell questi...</td>\n",
              "      <td>question whether morally right aim certain per...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>marriage license legal document allows couple ...</td>\n",
              "      <td>marriage license marriage certificate two diff...</td>\n",
              "      <td>marriage license legal document allows couple ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>function calling process invoking executing fu...</td>\n",
              "      <td>function calling process invoking function pro...</td>\n",
              "      <td>function calling process invoking executing fu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>creating test set rare category challenging ma...</td>\n",
              "      <td>building classifier rare category creating tes...</td>\n",
              "      <td>creating test set rare category challenging ma...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>best way travel tel aviv jerusalem depends per...</td>\n",
              "      <td>best way travel jerusalem depends personal pre...</td>\n",
              "      <td>best way travel tel aviv jerusalem depends per...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          response_a  \\\n",
              "0  question whether morally right aim certain per...   \n",
              "1  marriage license legal document allows couple ...   \n",
              "2  function calling process invoking executing fu...   \n",
              "3  creating test set rare category challenging ma...   \n",
              "4  best way travel tel aviv jerusalem depends per...   \n",
              "\n",
              "                                          response_b  \\\n",
              "0  ai personal belief opinion however tell questi...   \n",
              "1  marriage license marriage certificate two diff...   \n",
              "2  function calling process invoking function pro...   \n",
              "3  building classifier rare category creating tes...   \n",
              "4  best way travel jerusalem depends personal pre...   \n",
              "\n",
              "                                  combined_responses  \n",
              "0  question whether morally right aim certain per...  \n",
              "1  marriage license legal document allows couple ...  \n",
              "2  function calling process invoking executing fu...  \n",
              "3  creating test set rare category challenging ma...  \n",
              "4  best way travel tel aviv jerusalem depends per...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data[['response_a', 'response_b', 'combined_responses']].head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8iMXs4-ghdqv"
      },
      "outputs": [],
      "source": [
        "# Sample the data\n",
        "sampled_data = train_data.sample(n=10000, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1S9VmWuJkrrf",
        "outputId": "cf462519-b67e-437d-c3f5-52483546caa3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>model_a</th>\n",
              "      <th>model_b</th>\n",
              "      <th>prompt</th>\n",
              "      <th>response_a</th>\n",
              "      <th>response_b</th>\n",
              "      <th>winner_model_a</th>\n",
              "      <th>winner_model_b</th>\n",
              "      <th>winner_tie</th>\n",
              "      <th>combined_responses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>37379</th>\n",
              "      <td>2785062085</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>codellama-34b-instruct</td>\n",
              "      <td>hello world mean</td>\n",
              "      <td>hello world phrase used computer programming i...</td>\n",
              "      <td>hello world common phrase used display message...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>hello world phrase used computer programming i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>644</th>\n",
              "      <td>48259531</td>\n",
              "      <td>mistral-medium</td>\n",
              "      <td>gpt-4-0314</td>\n",
              "      <td>ran marathon weighting fast would run lose</td>\n",
              "      <td>difficult provide exact answer question many f...</td>\n",
              "      <td>accurately estimate much faster would run mara...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>difficult provide exact answer question many f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48496</th>\n",
              "      <td>3622731894</td>\n",
              "      <td>gpt-4-0314</td>\n",
              "      <td>gpt-3.5-turbo-0314</td>\n",
              "      <td>instruction describes task paired input provid...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12603</th>\n",
              "      <td>933663766</td>\n",
              "      <td>openchat-3.5</td>\n",
              "      <td>gpt-3.5-turbo-0613</td>\n",
              "      <td>run static analysis gcc qt creator</td>\n",
              "      <td>run static analysis gcc qt creator follow step...</td>\n",
              "      <td>run static analysis gcc qt creator follow step...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>run static analysis gcc qt creator follow step...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16697</th>\n",
              "      <td>1246768370</td>\n",
              "      <td>codellama-34b-instruct</td>\n",
              "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
              "      <td>music producer die</td>\n",
              "      <td>able provide information cause death publicly ...</td>\n",
              "      <td>really sorry ability access personal data ca p...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>able provide information cause death publicly ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25231</th>\n",
              "      <td>1877587731</td>\n",
              "      <td>wizardlm-70b</td>\n",
              "      <td>chatglm2-6b</td>\n",
              "      <td>write optimal sql query take data table client...</td>\n",
              "      <td>example optimal sql query retrieves sale volum...</td>\n",
              "      <td>optimal sql query provide sale volume per clie...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>example optimal sql query retrieves sale volum...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49278</th>\n",
              "      <td>3680864910</td>\n",
              "      <td>gpt-3.5-turbo-0125</td>\n",
              "      <td>mixtral-8x7b-instruct-v0.1</td>\n",
              "      <td>difference snail cat</td>\n",
              "      <td>snail cat two different type animal key differ...</td>\n",
              "      <td>snail cat different type animal belong differe...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>snail cat two different type animal key differ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37785</th>\n",
              "      <td>2813285142</td>\n",
              "      <td>llama-2-13b-chat</td>\n",
              "      <td>wizardlm-13b</td>\n",
              "      <td>summarize following text really felt like stru...</td>\n",
              "      <td>sure summary requested tan donated bone marrow...</td>\n",
              "      <td>individual named tan donated bone marrow boy f...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>sure summary requested tan donated bone marrow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49685</th>\n",
              "      <td>3711677764</td>\n",
              "      <td>vicuna-7b</td>\n",
              "      <td>vicuna-13b</td>\n",
              "      <td>fear v intimidation</td>\n",
              "      <td>fear intimidation two related distinct feeling...</td>\n",
              "      <td>fear intimidation related concept natural emot...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>fear intimidation two related distinct feeling...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35058</th>\n",
              "      <td>2601845218</td>\n",
              "      <td>claude-instant-1</td>\n",
              "      <td>qwen1.5-72b-chat</td>\n",
              "      <td>said born alone live alone die alone love frie...</td>\n",
              "      <td>quote often attributed philosopher orson welle...</td>\n",
              "      <td>quote often attributed orson welles american a...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>quote often attributed philosopher orson welle...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               id                 model_a                     model_b  \\\n",
              "37379  2785062085      gpt-3.5-turbo-0613      codellama-34b-instruct   \n",
              "644      48259531          mistral-medium                  gpt-4-0314   \n",
              "48496  3622731894              gpt-4-0314          gpt-3.5-turbo-0314   \n",
              "12603   933663766            openchat-3.5          gpt-3.5-turbo-0613   \n",
              "16697  1246768370  codellama-34b-instruct  mixtral-8x7b-instruct-v0.1   \n",
              "...           ...                     ...                         ...   \n",
              "25231  1877587731            wizardlm-70b                 chatglm2-6b   \n",
              "49278  3680864910      gpt-3.5-turbo-0125  mixtral-8x7b-instruct-v0.1   \n",
              "37785  2813285142        llama-2-13b-chat                wizardlm-13b   \n",
              "49685  3711677764               vicuna-7b                  vicuna-13b   \n",
              "35058  2601845218        claude-instant-1            qwen1.5-72b-chat   \n",
              "\n",
              "                                                  prompt  \\\n",
              "37379                                   hello world mean   \n",
              "644           ran marathon weighting fast would run lose   \n",
              "48496  instruction describes task paired input provid...   \n",
              "12603                 run static analysis gcc qt creator   \n",
              "16697                                 music producer die   \n",
              "...                                                  ...   \n",
              "25231  write optimal sql query take data table client...   \n",
              "49278                               difference snail cat   \n",
              "37785  summarize following text really felt like stru...   \n",
              "49685                                fear v intimidation   \n",
              "35058  said born alone live alone die alone love frie...   \n",
              "\n",
              "                                              response_a  \\\n",
              "37379  hello world phrase used computer programming i...   \n",
              "644    difficult provide exact answer question many f...   \n",
              "48496                                                      \n",
              "12603  run static analysis gcc qt creator follow step...   \n",
              "16697  able provide information cause death publicly ...   \n",
              "...                                                  ...   \n",
              "25231  example optimal sql query retrieves sale volum...   \n",
              "49278  snail cat two different type animal key differ...   \n",
              "37785  sure summary requested tan donated bone marrow...   \n",
              "49685  fear intimidation two related distinct feeling...   \n",
              "35058  quote often attributed philosopher orson welle...   \n",
              "\n",
              "                                              response_b  winner_model_a  \\\n",
              "37379  hello world common phrase used display message...               1   \n",
              "644    accurately estimate much faster would run mara...               1   \n",
              "48496                                                                  0   \n",
              "12603  run static analysis gcc qt creator follow step...               1   \n",
              "16697  really sorry ability access personal data ca p...               1   \n",
              "...                                                  ...             ...   \n",
              "25231  optimal sql query provide sale volume per clie...               0   \n",
              "49278  snail cat different type animal belong differe...               0   \n",
              "37785  individual named tan donated bone marrow boy f...               1   \n",
              "49685  fear intimidation related concept natural emot...               1   \n",
              "35058  quote often attributed orson welles american a...               0   \n",
              "\n",
              "       winner_model_b  winner_tie  \\\n",
              "37379               0           0   \n",
              "644                 0           0   \n",
              "48496               0           1   \n",
              "12603               0           0   \n",
              "16697               0           0   \n",
              "...               ...         ...   \n",
              "25231               1           0   \n",
              "49278               1           0   \n",
              "37785               0           0   \n",
              "49685               0           0   \n",
              "35058               0           1   \n",
              "\n",
              "                                      combined_responses  \n",
              "37379  hello world phrase used computer programming i...  \n",
              "644    difficult provide exact answer question many f...  \n",
              "48496                                                     \n",
              "12603  run static analysis gcc qt creator follow step...  \n",
              "16697  able provide information cause death publicly ...  \n",
              "...                                                  ...  \n",
              "25231  example optimal sql query retrieves sale volum...  \n",
              "49278  snail cat two different type animal key differ...  \n",
              "37785  sure summary requested tan donated bone marrow...  \n",
              "49685  fear intimidation two related distinct feeling...  \n",
              "35058  quote often attributed philosopher orson welle...  \n",
              "\n",
              "[10000 rows x 10 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "FBAPiERI6_8n"
      },
      "outputs": [],
      "source": [
        "# Vectorize text using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(sampled_data['combined_responses'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eHfbQ9Fk6_8n",
        "outputId": "70130b39-ffb3-476f-e944-0505136c04b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1],\n",
              "       ...,\n",
              "       [1, 0, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 0, 1]], dtype=int64)"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Target variable\n",
        "sampled_data[['winner_model_a', 'winner_model_b', 'winner_tie']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "mqiJCQjN6_8n"
      },
      "outputs": [],
      "source": [
        "# Encode target variable\n",
        "sampled_data['winner'] = sampled_data[['winner_model_a', 'winner_model_b', 'winner_tie']].idxmax(axis=1)\n",
        "sampled_data['winner'] = sampled_data['winner'].map({'winner_model_a': 0, 'winner_model_b': 1, 'winner_tie': 2})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "60c2UJIL6_8n"
      },
      "outputs": [],
      "source": [
        "# target variable\n",
        "y = sampled_data['winner'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ejii18pk6_8n"
      },
      "outputs": [],
      "source": [
        "# train_test\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCdClFKz6_8n",
        "outputId": "3eab1461-3a99-46e2-b6e4-6385bd117fb0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((8000, 54992), (2000, 54992), (8000,), (2000,))"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check the shapes\n",
        "X_train.shape, X_val.shape, y_train.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJ0aU8sM6_8n"
      },
      "source": [
        "### Model 1: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "zKR1XDQj6_8o",
        "outputId": "e26ef63d-1b17-420d-dc37-26dadd682c38"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000, multi_class=&#x27;multinomial&#x27;)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(max_iter=1000, multi_class='multinomial')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Initialize the model\n",
        "model_LR = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
        "\n",
        "# Train the model\n",
        "model_LR.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ir5XtApX6_8o"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the validation set\n",
        "y_pred_LR = model_LR.predict_proba(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x4obCHE6_8o",
        "outputId": "efd4d192-7782-4795-b66a-e501f47f9569"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Log Loss: 1.1030934797200938\n"
          ]
        }
      ],
      "source": [
        "# Calculate log loss\n",
        "log_loss_score_LR = log_loss(y_val, y_pred_LR)\n",
        "print(f'Log Loss: {log_loss_score_LR}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DVaDl256_8o",
        "outputId": "eb5a98e5-23e4-419f-b68e-9e7cd87c66fa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# Load the tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Oa2ULXlM6_8o"
      },
      "outputs": [],
      "source": [
        "# Tokenize the text data\n",
        "def encode_data(texts):\n",
        "    return tokenizer(texts, padding=True, truncation=True, return_tensors='pt')\n",
        "\n",
        "train_encodings = encode_data(sampled_data['combined_responses'].tolist())\n",
        "labels = torch.tensor(sampled_data['winner'].values, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jhjjA_rL6_8o"
      },
      "outputs": [],
      "source": [
        "# Split the data into training and validation sets\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(sampled_data['combined_responses'], labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Tokenize the split text data\n",
        "train_encodings = encode_data(train_texts.tolist())\n",
        "val_encodings = encode_data(val_texts.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HA8dl1dO6_8o"
      },
      "outputs": [],
      "source": [
        "# Define a custom dataset\n",
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "         \"\"\"\n",
        "        Initializes the CustomDataset with encodings and labels.\n",
        "\n",
        "        Parameters:\n",
        "        encodings (dict): Encoded input data.\n",
        "        labels (torch.Tensor): Corresponding labels for the input data.\n",
        "        \"\"\"\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Retrieves the item (encoding and label) at the specified index.\n",
        "\n",
        "        Parameters:\n",
        "        idx (int): Index of the item to retrieve.\n",
        "\n",
        "        Returns:\n",
        "        dict: A dictionary containing the encoding and label for the specified index.\n",
        "        \"\"\"\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        item['labels'] = self.labels[idx]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the number of items in the dataset.\n",
        "        \n",
        "        \"\"\"\n",
        "        return len(self.labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FmHyAPfa6_8o"
      },
      "outputs": [],
      "source": [
        "#  Create a CustomDataset object for the training and validation sets\n",
        "train_dataset = CustomDataset(train_encodings, train_labels)\n",
        "val_dataset = CustomDataset(val_encodings, val_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "T2Dm0RcS6_8o"
      },
      "outputs": [],
      "source": [
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        "    logging_steps=10\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "7sBk85Ww6_8o"
      },
      "outputs": [],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khUgjKtu6_8o",
        "outputId": "ab3bec23-c022-4cd0-df46-6604896319e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Move model to GPU if available\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eNd_F_5L6_8o",
        "outputId": "e9bb89e2-3a14-4c45-f46f-645869776e86"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='64' max='3000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [  64/3000 10:25 < 8:13:49, 0.10 it/s, Epoch 0.06/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.101000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.113500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>1.114800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>1.122400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>1.067500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>1.113800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "id": "MhoT7wmF6_8o",
        "outputId": "29e7fa5a-5855-48b2-8b0d-723d35b69703"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='250' max='250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [250/250 00:55]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 1.0958130359649658,\n",
              " 'eval_runtime': 56.1869,\n",
              " 'eval_samples_per_second': 35.595,\n",
              " 'eval_steps_per_second': 4.449,\n",
              " 'epoch': 3.0}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGKgvqAlAOb6"
      },
      "source": [
        "### Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kw_PBvwK_-Sy"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess test data\n",
        "test_data = pd.read_parquet('test.parquet', engine='pyarrow')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4Uftc_7ANx7"
      },
      "outputs": [],
      "source": [
        "# Clean the text data\n",
        "test_data['prompt'] = test_data['prompt'].apply(clean_text)\n",
        "test_data['response_a'] = test_data['response_a'].apply(clean_text)\n",
        "test_data['response_b'] = test_data['response_b'].apply(clean_text)\n",
        "test_data['combined_responses'] = test_data['response_a'] + \" \" + test_data['response_b']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-v_8TogzAIsr"
      },
      "outputs": [],
      "source": [
        "# Vectorize test data\n",
        "X_test = vectorizer.transform(test_data['combined_responses'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgxxb7gjAIpL",
        "outputId": "34e0d5b1-0d0b-4674-84af-738cef33ee8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Predictions (Logistic Regression): [[0.18739054 0.36258478 0.45002467]\n",
            " [0.35477295 0.4159459  0.22928115]\n",
            " [0.46346236 0.26345956 0.27307808]]\n"
          ]
        }
      ],
      "source": [
        "# Make predictions on the test data using Logistic Regression model\n",
        "y_test_pred_LR = model_LR.predict_proba(X_test)\n",
        "print(f'Test Predictions (Logistic Regression): {y_test_pred_LR}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOQugzHOAInH"
      },
      "outputs": [],
      "source": [
        "# Tokenize the test data\n",
        "test_encodings = encode_data(test_data['combined_responses'].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0cW87x2_-8c"
      },
      "outputs": [],
      "source": [
        "# Move test encodings to device\n",
        "test_encodings = {key: val.to(device) for key, val in test_encodings.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gE-o-Hd6AURS"
      },
      "outputs": [],
      "source": [
        "# Make predictions on the test data using BERT model\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    outputs = model(**test_encodings)\n",
        "    predictions = torch.nn.functional.softmax(outputs.logits, dim=-1).cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RtU-IJ1bAWG-"
      },
      "outputs": [],
      "source": [
        "# Prepare the submission file\n",
        "submission = pd.DataFrame(predictions, columns=['winner_model_a', 'winner_model_b', 'winner_tie'])\n",
        "submission.insert(0, 'id', test_data['id'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ppsujL4ZAXdN",
        "outputId": "3c129761-cb9a-4e1d-a308-a5cf18c1a58e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Submission file created!\n"
          ]
        }
      ],
      "source": [
        "# Save the submission file\n",
        "submission.to_csv('submission.csv', index=False)\n",
        "print('Submission file created!')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
